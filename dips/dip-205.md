---
dip: 205
title: State Sync v2: Strategies & Framework
authors: Joshua Lind (@joshlind)
status: Draft
type: Standard
created: 08/11/2021
---

# Summary

* *Problem*: State sync only offers a single primitive strategy for keeping nodes up-to-date. This strategy is slow (i.e., it requires syncing and executing all transactions from genesis), expensive (i.e., it requires downloading, executing and storing the entire transaction history), inflexible (i.e., it is unable to adapt to different use-cases and requirements) and brittle (i.e., the implementation tightly couples Diem components and Diem nodes).
* *Solution*: We propose a new state sync framework that supports multiple state sync strategies based on use-cases. The strategies trade-off security, performance and resources. Strategies include: syncing from genesis, syncing directly from a waypoint and syncing without executing. The new framework decouples intra-node components (e.g., state sync and storage) and removes coupling between Diem nodes (e.g., allowing additional strategies to be introduced without breaking backward compatibility).

# Motivation and Goals

To improve state synchronization in the Diem blockchain, specifically:
  * *Performance*: the amount of time taken to synchronize to the head of the blockchain and stay synchronized.
  * *Resources*: the CPU, storage and network costs required to synchronize and stay synchronized.
  * *Flexibility*: the ability to support different syncing strategies based on use-cases and needs.
  * *Extensibility*: the ability to add, remove and change syncing strategies without impacting all intra-node components and backward compatibility.

# Background and Problem

State sync is the core component responsible for keeping Diem nodes (e.g., fullnodes) up-to-date with the blockchain (e.g., when new transactions are committed by validators). State sync is currently limited to a single strategy that syncs to the head of the blockchain by downloading, verifying, executing and storing all transactions since genesis. This strategy is highly coupled with the current implementation of Diem and cannot be easily changed without breaking backward compatibility. This makes state sync:
  * *Slow*: At best, state sync can process < 2k tx/s. Users must wait hours to synchronize transactions accumulated over days. This has resulted in workarounds that require human intervention (e.g., backup and restore).
  * *Expensive*: State sync introduces a large resource cost/barrier for users. Nodes must download, verify, execute and store all transactions before having access to the latest blockchain state. Moreover, state sync requires access to a Move VM, which is specialized and makes third-party fullnodes expensive to develop/deploy.
  * *Inflexible*: State sync offers only a single syncing strategy, despite use-cases having different security, performance and resource requirements. Different use-cases may wish to optimize for different goals (e.g., performance).
  * *Brittle*: State sync is implemented in a way that tightly couples intra-node components as well as imposes coupling between Diem nodes. This makes it difficult to improve components and strategies, resulting in legacy limitations that are unable to be addressed without breaking backward compatibility.

# Solution: A New State Sync Framework

To solve this, we propose deprecating State Sync v1.1 and adding a new state sync framework that supports several different strategies. We discuss the strategies and framework below.

## Bootstrapping & Syncing Strategies

We categorize the proposed strategies based on two distinct operations: (i) Initial *bootstrapping*: that is, getting the node up-to-date to a version, `V` (e.g., getting all account states at `V`); and (ii) Continuous *syncing*: that is, keeping the node up-to-date (e.g., once bootstrapped to `V`, continuously synchronizing account states with increasing versions `V’`, `where V’ > V`). 

Note: the strategies below assume that each node will hold and maintain all account states. Other strategies (including partial account state synchronization) can be supported at a later date, with a new DIP.

*Bootstrapping Strategies*: Moving from B1 → B4 we increase performance at the cost of security.
  * B1: Transaction execution from genesis
    * A node will be given a genesis blob and a waypoint ledger info (i.e., an epoch ending ledger info with signatures at version `W`). It will fetch all transactions (from genesis), re-execute the transactions and verify the execution against the results committed by the validators (i.e., using signed ledger infos). Once it reaches the waypoint, it will verify the waypoint and account states and finish, ending at version `W`.
  * B2: Transaction outputs from genesis (Non-executing)
    * A node will be given a genesis blob and a waypoint ledger info (at version `W`). It will fetch all transaction outputs (starting from genesis), apply the transaction outputs and verify the outputs against the results committed by the validators (i.e., using signed ledger infos). Once it reaches the waypoint, it will verify the waypoint and account states and finish bootstrapping, ending at version `W`.
  * B3: Epoch-skipping to a waypoint
    * A node will be given a genesis blob and a waypoint ledger info (at version `W`). It will fetch and verify every epoch ending ledger info from genesis up to the waypoint. Once it has verified that the waypoint is valid, it may continue verifying epoch ending ledger infos until it reaches one (at version `V`)  where it will download all account states, verify the state and finish bootstrapping at version `V`, where, `V >= W`.
        * Note: the reason that the node may continue epoch skipping until  `V` (as opposed to downloading all account states at `W`) is data availability. An old waypoint may be impossible to sync from (see below).
  * B4: Instant sync with trusted waypoints
    * A node will be given a waypoint ledger info (at version `W`). It will verify epoch ending ledger infos starting from the waypoint until it reaches one (at version `V`) where it will download all account states, verify the state and finish bootstrapping at version `V`, where, `V >= W`.

*Syncing Strategies*: Moving from S1 → S2 we increase performance at the cost of security.

  * S1: Transaction execution
    * Once a node has been bootstrapped to version `V`, it will continue to fetch, execute and verify transactions for increasing versions `V’`, where `V’ > V`. Note: this is how state sync works today.
  * S2: Transaction outputs (Non-executing)
    * Once a node has been bootstrapped to version `V`, it will begin syncing and applying transaction outputs directly for increasing versions `V’`, where `V’ > V`, i.e., request, apply and verify transaction outputs.

## State Sync Framework API

To support these syncing strategies and improve the flexibility and extensibility of state sync, we propose a new state sync framework. This framework consists of a new *inter-node API*: the state sync API between Diem nodes, e.g., using RPCs.

Note: each API call may not return immediately, e.g., to support long polling. Moreover, each API call may also return an error, e.g., in the case that the API call is unsupported or the node does not retain the requested data (see the data availability discussion, further below).

The proposed API is as follows:
  * (1) `get_state_sync_summary() → Result<StateSyncSummary, Error>`
    * This API call returns a `StateSyncSummary`, which contains a collection of useful information about the current state of the peer, e.g., it can be used (periodically) to determine how far ahead (or behind) the peer is and also what type of API requests the peer can serve, e.g.,:
        ```
            pub struct StateSyncSummary {
                state_sync_version: StateSyncVersion, // the state sync version 
                
                highest_version: u64, // the highest version currently synced
                highest_epoch: u64, // the highest epoch currently synced
                
                lowest_txn_version: u64, // the earliest transaction stored
                lowest_txn_output_version: u64, // the earliest txn output stored
                lowest_state_snapshot_version: u64, // the earliest snapshot stored
                lowest_epoch_ending_li_version: u64, // the earliest epoch ending ledger info stored
            
                max_outgoing_txn_chunk_size: u64, // the max outgoing txn chunk size that can be served
                max_outgoing_txn_output_chunk_size: u64, // similar to above but for txn outputs
                max_outgoing_state_snapshot_chunk_size: u64, // similar to above but for account states
                max_outgoing_epoch_ending_chunk_size: u64, // similar to above but ledger infos that end epochs
                ...
            }
      ```
            
  * (2) `get_transactions_chunk(known_version, max_chunk_size, target) → Result<(TransactionListWithProof, LedgerInfoWithSignatures), Error>`
    * This API call returns a list of transactions and a proof starting at `known_version` (where the transaction list length <= `max_chunk_size`). The list proof is verified against the returned ledger info with signatures using the transaction info accumulator. `target` may specify a version or ledger info to sync to.

  * (3) `get_txn_outputs_chunk(known_version, known_epoch, max_chunk_size, target) → Result<(Vec<TransactionOutput>, TransactionOutputListProof, LedgerInfoWithSignatures), Error>`
    * This API call is similar to `get_transactions_chunk(...)`, but it returns a list of transaction outputs (after each transaction is executed). The transaction outputs can be verified using the transaction outputs list proof — there are two possible ways to verify transaction output correctness:
        * First, speculatively apply each transaction output to storage and verify the resulting state and event root hashes using the given ledger info. If a failure occurs, the transaction output is incorrect: the chunk should be rejected and any storage modifications reverted.
        * Second, to avoid having to speculatively apply each transaction output, we could modify the Diem proofs (e.g., update `TransactionInf`o to include a hash of each `TransactionOutput`). This would allow nodes to verify that transaction outputs are correct using the transaction info accumulator and would avoid having to do unnecessary work. However, this would break backward compatibility.
    * Note: this API call implicitly assumes that only transaction outputs will be served (transactions themselves will not). The motivation behind this is to separate transactions and transaction outputs, i.e., nodes should have the ability to decide whether to store one type of data, or both. If a node wishes to fetch both, it will also need to call `get_transactions_chunk()` above. We note that this also makes sense from a backward compatibility perspective: nodes already deployed today may wish to start storing transaction outputs, but it’s unlikely that they will want to backfill transaction outputs for all the transactions they already hold.
* (4) `get_epoch_ending_ledger_infos(start_epoch, end_epoch, max_chunk_size) → Result<Vec<LedgerInfoWithSignatures>, Error>`
    * This API call returns a list of ledger info with signatures, starting at the given epoch and ending at `min(end_epoch, start_epoch + max_chunk_size)`. This can be used to skip epochs.
* (5) `get_account_states_chunk(version, start_account_index, start_account_key, max_chunk_size) → Result<AccountStateChunk, Error>`
    * This API call returns an `AccountStateChunk`:
        ```
            pub struct AccountStateChunk {
                first_index: u64, // first account index in chunk
                last_index: u64, // last account index in chunk
                first_key: HashValue, // first account key in chunk
                last_key: HashValue, // last account key in chunk
                account_blobs: HashMap<HashValue, AccountStateBlob>,
                proof: SparseMerkleRangeProof // proves chunk in state
            }
        ```
    * The chunk contains a part of the account states tree at a specified version. The proof can be used to verify the chunk is included in the state root hash, e.g., using the `TransactionInfo` accumulator in a ledger info. Many chunks together should form the entire account states tree.

# Data Availability and Resource Usage

To support the strategies outlined above, Diem nodes will now need to maintain and serve different types of data: (i) transactions; (ii) transaction outputs; (iii) epoch ending ledger infos; and (iv) account states. Currently, Diem nodes provide the following guarantees about data availability:

1. All Diem nodes store all transactions (i.e., the entire history since genesis), including transaction infos and events.
2. Diem nodes do not store transaction outputs.
3. All Diem nodes store all epoch ending ledger infos (since genesis).
4. Diem nodes do not store account states for all versions (e.g., due to pruning and/or backup and restore). Nodes can only guarantee to store account states for their most recent version and a configurable history, i.e., pruning window.

To support the syncing strategies identified above, we now note that:

1. Diem nodes can no longer guarantee to store all transactions and epoch ending ledger infos since genesis, breaking guarantees 1 and 3, above. For example, strategies B3 and B4 violate these assumptions.
2. Diem nodes will need to be updated to store transaction outputs, alongside each transaction.
3. To serve account states between Diem nodes (i.e., support strategies B3 and B4), the pruning window on each node needs to be sufficiently long such that nodes are able to serve all account states at a specified version. If the pruning window is too aggressive, pruning my occur while serving the account states.
4. Diem nodes will need to manage state about their peers to avoid situations where data is no longer available and the node cannot synchronize.

## Data Availability Concerns

It is evident that Diem nodes will not be able to service all state sync requests: some nodes may have pruned required data, while other nodes may never have held that data to begin with. To address this, we note that the `get_state_sync_summary()` call for the inter-node state sync API provides a means for Diem nodes to identify how a peer has bootstrapped, where it is currently synced to, and what type of syncing strategy it is using. Moreover, it provides additional information about what historical data the peer holds, e.g., the earliest transaction, account state snapshot and epoch ending ledger info it can serve.

Using this information, Diem nodes should be able to determine very quickly whether or not they are likely to make progress based on their current bootstrapping and syncing strategies and the state of the peers around them. If a node is unlikely to make progress, this should be flagged to the operator who will need to decide what to do and whether or not adopt a different syncing strategy.

# Additional Considerations

## Backward Compatibility: Deprecating State Sync v1
   
To deprecate state sync v1 and maintain backward compatibility between Diem nodes, we propose running both versions of state sync on a single node simultaneously at first (for a fixed period of time). Each state sync version will be completely separate applications, meaning messages will be routed separately to each protocol by the networking layer:   
   * Diem nodes running only state sync v1 will make outbound sync requests to peers and respond to inbound requests from peers, as normal (i.e., how state sync v1 operates today).
   * Diem nodes running both state sync v1 and state sync v2 will run state sync v1 in a restricted and wrapped mode, where:
       * State sync v1 will only respond to inbound requests from peers by reading from storage (as normal) but be prohibited from automatically sending out synchronization requests to peers or writing to storage.
       * State sync v2 will always attempt to make progress by sending state sync requests to peers that support v2. However, if no peers support v2 (and the node has been configured to synchronize by executing transactions!), state sync v2 will manually invoke state sync v1 to send out synchronization requests to update the node. That is, until any peer is found that supports v2. We note:
           * At least one Diem node (validator or fullnode) needs to be up-to-date and deployed with both versions of state sync before peers can utilize the new strategies (i.e., B2, B3, B4 and S2). Otherwise, if all the peers of a Diem node are only running state sync v1, the node will only be able to synchronize using B1 and S1.

## Justifying the Bootstrapping and Syncing Strategies
   
   The set of strategies presented above (i.e., B1 → B4 and S1 → S2) were chosen as high-impact strategies that should be supported by the first iteration of the new state sync framework. We justify this choice with the following observations:
   
   * To maintain backward compatibility, B1 and S1 need to be supported. Moreover, it seems reasonable that users may wish to execute all transactions since genesis, e.g., to: (i) initially verify the blockchain is legitimate and untarnished; and (ii) implement innovative services (e.g., blockchain explorers, transaction visualization and analytics, provisioning engines, etc.) and conduct research.
   * Given that synchronization performance is currently a significant concern with state sync v1, it is reasonable to support strategies that: (i) provide nodes with the latest blockchain state as quickly as possible; and (ii) keep the nodes up-to-date as quickly and efficiently as possible: This means:
       * Skipping as much historical blockchain data as possible while still maintaining appropriate security guarantees about the blockchain. This makes B3 and B4 reasonable candidates.
       * Supporting incremental updates to existing blockchain data (i.e., not having to treat each version of the blockchain as completely new or independent). This makes S1 and S2 reasonable candidates.
   * Given that state sync requires both CPU and networking resources, it seems reasonable to support both B1/S1 and B2/S2 and allow users to choose the strategy based on their resource constraints.
   
## Default Bootstrapping and Syncing Strategies
   
   We make the following suggestions for the default strategies that should be deployed on each Diem node, based on the node’s role in the network:
   
   * *Validators*: Validators decide which transactions to commit. As such, they execute all transactions, allowing them to store and serve all types of data. However, validators also rely on state sync to synchronize under failure scenarios (e.g., if they’ve fallen behind the rest of the validator set). We make two observations:
       * Given that validators are the first source of data in Diem, they must store and serve all types of data to clients (i.e., validator fullnodes). However, once clients have fetched this data, there is no need for validators to retain it. As such, we recommend that validators adopt aggressive pruning strategies to remove old data.
       * If a validator encounters a failure where it must rely on state sync, the validator should be brought up-to-speed as quickly as possible. As a result, a validator may avoid executing transactions temporarily and sync via transaction outputs (i.e., S2) to catch up quickly. This assumes the missing data is not significantly large. However, if the validator suffers a longer failure, where it is missing a large amount of data, it may instead adopt a cheap bootstrapping strategy (e.g., B3) to get all account states at the beginning of the latest epoch and then synchronize quickly to get up-to-date (e.g., using S2). 
   * *Validator fullnodes*: Validator fullnodes are the sole source of blockchain data for the public (e.g., fullnodes and clients in the wild). As such, they will need to serve all types of data and API requests and retain this data for longer periods of time. Validator fullnodes should likely bootstrap and synchronize using either: (i) B1 and S1; or: (ii) B2 and S2 — fetching both transactions and transaction outputs. Likewise, they should avoid pruning data too aggressively to ensure they can satisfy client requests.
   * *Public fullnodes*: Public fullnodes in the wild will mostly likely adopt a range of strategies, depending on the use case. We imagine that most fullnodes will employ a form of quick synchronization (e.g., B3) to get up-to-speed with the network, and then employ either S1 or S2 to stay synchronized.
